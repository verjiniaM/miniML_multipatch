{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring training data for miniML. After the plot has been opened, it can be closed at any time and e.g. go to a different starting index. As long as the kernel does not crash, the changes in the scores will be retained and can just be saved at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applied changes**\n",
    "\n",
    "first round of scoring for nice events (1) and false positives (0), everything else is left in blue\n",
    "second round of scoring - not_so_nice events (1) and noise (0)\n",
    "saved for each file individually in a desginated folder\n",
    "after that each file needs to be moved (manually for now) to the everything_scored folder\n",
    "- otherwise the indexing in the second code cell won't work\n",
    "\n",
    "script to go thourt all and count\n",
    "script to collect all all categories and run though them once again\n",
    "script to collected all the category separated files into one complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from ScoringPanel import ScoringPanel\n",
    "import numpy as np\n",
    "import PyQt5 \n",
    "\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "plt.rcParams['axes.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = '/Users/verjim/miniML_multipatch/model_training/extract_training_data/output/Nov_2024_train/'\n",
    "\n",
    "# all_files = os.listdir(output_folder)\n",
    "# h5s_ = sorted([x for x in all_files if x[-3:] == '.h5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1144, 750) (1144,)\n"
     ]
    }
   ],
   "source": [
    "# Load data to be scored\n",
    "file_path = '/Users/verjim/miniML_data/data/model_training_round_2/2024_Nov_11_all_types_of_events_to_check.h5'\n",
    "with h5py.File(file_path, 'r') as f:\n",
    "    x = f['events'][:]\n",
    "    y = f['scores'][:]\n",
    "    labels = f['labels'][:]\n",
    "    fn_chan = f['filename and chan'][:]\n",
    "\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the interactive plot for scoring.\n",
    "- To go to the next/previous event, use forward/backward arrows on the keyboard or the scroll wheel.\n",
    "- To change the score, press 'm' on the keyboard.\n",
    "\n",
    "\n",
    "The scores mean the following:\n",
    "- 0: red, not an event of interest\n",
    "- 1: black, event of interest\n",
    "- 2: blue, unclear\n",
    "\n",
    "For training the model, there should be no events with scores 2 in the dataset. We added this so one can mark them and either exclude them or come back to them at a later time point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "# Open plot for scoring\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "tracker = ScoringPanel(fig, ax, x, y, labels, fn_chan, start_ind = 611)\n",
    "fig.canvas.mpl_connect('key_press_event', tracker.onclick)\n",
    "fig.canvas.mpl_connect('scroll_event', tracker.onscroll)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything saved to /Users/verjim/miniML_multipatch/model_training/extract_training_data/output/Nov_2024_train/\n"
     ]
    }
   ],
   "source": [
    "zeros = x[np.where(y==0)].copy()\n",
    "zeros_score = y[y == 0].copy()\n",
    "fn_chan_0 = fn_chan[np.where(y==0)].copy()\n",
    "\n",
    "ones = x[np.where(y==1)].copy()\n",
    "ones_score = y[y == 1].copy()\n",
    "fn_chan_1 = fn_chan[np.where(y==1)].copy()\n",
    "\n",
    "x_save = np.concatenate([zeros[:450], ones[:450]], axis = 0)\n",
    "y_save = np.concatenate([zeros_score[:450], ones_score[:450]], axis = 0)\n",
    "fn_chan_save = np.concatenate([fn_chan_0[:450], fn_chan_1[:450]], axis = 0)\n",
    "\n",
    "# suffling the data\n",
    "indices = np.random.permutation(len(x))\n",
    "\n",
    "# Apply the permutation to shuffle x and y\n",
    "x_shuffled = x_save[indices]\n",
    "y_shuffled = y_save[indices]\n",
    "fn_chan_shuffled = fn_chan_save[indices]\n",
    "\n",
    "# save the eevents and the lbels\n",
    "\n",
    "with h5py.File(output_folder  + '_all_types_of_events_checked_to_train.h5', 'w') as f:\n",
    "    f.create_dataset(\"events\", data = x_shuffled)\n",
    "    f.create_dataset(\"scores\", data = y_shuffled)\n",
    "    f.create_dataset(\"filename and chan\", data = fn_chan_shuffled)\n",
    "\n",
    "print(f\"Everything saved to {output_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the following code is used when training the model for the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives = x[np.where(y==0)].copy()\n",
    "false_positives_score = y[y == 0].copy()\n",
    "\n",
    "okey_events = x[np.where(y==1)].copy()\n",
    "okey_events_score = y[y == 1].copy()\n",
    "\n",
    "# nice_events = x[np.where(y==1)].copy()\n",
    "# nice_events_score = y[y == 1].copy()\n",
    "\n",
    "# unscored_x = x[np.where(y==2)].copy()  \n",
    "# unscored = y[y == 2].copy()\n",
    "\n",
    "# if len(false_positives) + len(nice_events) + len(unscored) == len(y):\n",
    "#     print('free to continue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save modified dataset. Changes will only be saved after running this cell.\n",
    "\n",
    "with h5py.File(output_folder + 'false_positives/' +  i[:-3] + 'false_pos.h5', 'w') as f:\n",
    "    f.create_dataset(\"events\", data = false_positives)\n",
    "    f.create_dataset(\"scores\", data = false_positives_score)\n",
    "\n",
    "\n",
    "with h5py.File(output_folder + 'not_so_nice_events/' + i[:-3] + '_okey.h5', 'w') as f:\n",
    "    f.create_dataset(\"events\", data = okey_events)\n",
    "    f.create_dataset(\"scores\", data = okey_events_score)\n",
    "\n",
    "# with h5py.File(output_folder + 'nice_events/' + i[:-3] + '_nice.h5', 'w') as f:\n",
    "#     f.create_dataset(\"events\", data = nice_events)\n",
    "#     f.create_dataset(\"scores\", data = nice_events_score)\n",
    "\n",
    "# with h5py.File(output_folder + 'unscored_round_1/' + i[:-3] + '_unscored.h5', 'w') as f:\n",
    "#     f.create_dataset(\"events\", data = unscored_x)\n",
    "#     f.create_dataset(\"scores\", data = unscored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previously unscored, extract not so nice/ clear events and noise\n",
    "\n",
    "The scores mean the following:\n",
    "- 0: red, noise\n",
    "- 1: black, not so nice event\n",
    "- 2: blue, unclear, delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "# Open plot for scoring\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "tracker = ScoringPanel(fig, ax, unscored_x, unscored, start_ind=0)\n",
    "fig.canvas.mpl_connect('key_press_event', tracker.onclick)\n",
    "fig.canvas.mpl_connect('scroll_event', tracker.onscroll)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = unscored_x[np.where(unscored==0)].copy()\n",
    "noise_score = unscored[unscored == 0].copy()\n",
    "okey_events = unscored_x[np.where(unscored==1)].copy()\n",
    "okey_events_score = unscored[unscored == 1].copy()\n",
    "\n",
    "rest_x = unscored_x[np.where(unscored==2)].copy()  \n",
    "rest = unscored[unscored == 2].copy()\n",
    "\n",
    "if len(noise) + len(okey_events) + len(rest) == len(unscored):\n",
    "    print('free to continue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(output_folder + 'noise/' +  i[:-3] + 'noise.h5', 'w') as f:\n",
    "    f.create_dataset(\"events\", data = noise)\n",
    "    f.create_dataset(\"scores\", data = noise_score)\n",
    "\n",
    "with h5py.File(output_folder + 'not_so_nice_events/' + i[:-3] + '_okey.h5', 'w') as f:\n",
    "    f.create_dataset(\"events\", data = okey_events)\n",
    "    f.create_dataset(\"scores\", data = okey_events_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move the file to the scored folder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting all the scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type = 'false_positives/' #not_so_nice_events/, 'false_positives/'\n",
    "\n",
    "output_folder = '/Users/verjim/miniML_multipatch/model_training/extract_training_data/output/Oct_2024_train/' + type\n",
    "all_files = os.listdir(output_folder)\n",
    "\n",
    "# all_files = sorted([x for x in all_files if x[-12:] == 'datanoise.h5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for fn in all_files:\n",
    "    file_path = output_folder + fn\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        x = f['events'][:]\n",
    "        y = f['scores'][:]\n",
    "    counter += len(x)\n",
    "\n",
    "print(counter)\n",
    "\n",
    "# to 12: FP - 564, nice - 308, noise - 93, not_so_nice - 334"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count for each event type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type = 'nice_events/' # 'not_so_nice_events/', 'false_positives/', 'noise/', 'nice_events/'\n",
    "\n",
    "scores_dict = {'false_positives/': 0, 'not_so_nice_events/': 1 , 'noise/': 0,'nice_events/': 1}\n",
    "\n",
    "output_folder = '/Users/verjim/miniML_multipatch/model_training/extract_training_data/output/Oct_2024_train/'\n",
    "all_files = os.listdir(output_folder + type)\n",
    "\n",
    "if '.DS_Store' in all_files:\n",
    "    all_files.remove('.DS_Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, file in enumerate(all_files):\n",
    "    fn = output_folder + type + file\n",
    "    count = 0\n",
    "    if i == 0:\n",
    "        with h5py.File(fn, 'r') as f:\n",
    "            x = f['events'][:][:, :750]\n",
    "            y = f['scores'][:]\n",
    "    else:\n",
    "        with h5py.File(fn, 'r') as f:\n",
    "            x = np.concatenate((x, f['events'][:][:, :750]))\n",
    "            y = np.concatenate((y, f['scores'][:]), axis = None)\n",
    "\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "# Open plot for scoring\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "tracker = ScoringPanel(fig, ax, x, y, start_ind = 0)\n",
    "fig.canvas.mpl_connect('key_press_event', tracker.onclick)\n",
    "fig.canvas.mpl_connect('scroll_event', tracker.onscroll)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = scores_dict[type]\n",
    "\n",
    "events_keep = x[np.where(y==score)].copy()\n",
    "scores_keep = y[y == score].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(output_folder + type[:-1] + '_complete.h5', 'w') as f:\n",
    "    f.create_dataset(\"events\", data = events_keep)\n",
    "    f.create_dataset(\"scores\", data = scores_keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect all into one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = '/Users/verjim/miniML_multipatch/model_training/extract_training_data/output/Oct_2024_train/'\n",
    "all_files = os.listdir(output_folder)\n",
    "\n",
    "collected = [x for x in all_files if x[-3:] == '.h5']\n",
    "\n",
    "dict_nums = {'false': 500, 'not_s': 300, 'noise': 100, 'nice_': 300}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(x[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, file in enumerate(collected):\n",
    "    fn = output_folder + file\n",
    "    count = dict_nums[file[:5]]\n",
    "    if i == 0:\n",
    "        with h5py.File(fn, 'r') as f:\n",
    "            x = f['events'][:count]\n",
    "            y = f['scores'][:count]\n",
    "    else:\n",
    "        with h5py.File(fn, 'r') as f:\n",
    "            x = np.concatenate((x, f['events'][:count]))\n",
    "            y = np.concatenate((y, f['scores'][:count]), axis = None)\n",
    "\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(output_folder + 'complete_training_dataset.h5', 'w') as f:\n",
    "    f.create_dataset(\"events\", data = x)\n",
    "    f.create_dataset(\"scores\", data = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting some scored data for lab seminar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Users/verjim/miniML_multipatch/model_training/training_data/complete_training_dataset.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1199, 750) (1199,)\n"
     ]
    }
   ],
   "source": [
    "# Load data to be scored\n",
    "with h5py.File(file_path, 'r') as f:\n",
    "    x = f['events'][:]\n",
    "    y = f['scores'][:]\n",
    "\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "labels = 'x' * x.shape[0]\n",
    "fn_chan = 'x' * x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "# Open plot for scoring\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "tracker = ScoringPanel(fig, ax, x, y, labels, fn_chan, start_ind = 611)\n",
    "fig.canvas.mpl_connect('key_press_event', tracker.onclick)\n",
    "fig.canvas.mpl_connect('scroll_event', tracker.onscroll)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
