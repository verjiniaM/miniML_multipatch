{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script to automatically extract training data based on template matching from a single input file. There is a separate script (generate_training_data_multiple_recordings.py) to extract training data from several files or recordings. Here, we use a single file and plot the result obtained by template matching as well as the template. Can be used to adjust parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../core/')\n",
    "\n",
    "from miniML import MiniTrace\n",
    "import template_matching as tm\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "import ast\n",
    "import PyQt5 #  to be able to use interactive plots \n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfect_traces_df = pd.read_excel('/Users/verjim/laptop_D_17.01.2022/Schmitz_lab/results/human/data/summary_data_tables/events/perfect_traces.xlsx')\n",
    "patcher_dict = {'Verji':'data_verji/', 'Rosie':'data_rosie/'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'patcher_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m unit \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpA\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m\n\u001b[0;32m----> 7\u001b[0m filename  \u001b[38;5;241m=\u001b[39m path \u001b[38;5;241m+\u001b[39m \u001b[43mpatcher_dict\u001b[49m[perfect_traces_df\u001b[38;5;241m.\u001b[39mpatcher[a]] \u001b[38;5;241m+\u001b[39m perfect_traces_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOP\u001b[39m\u001b[38;5;124m'\u001b[39m][a] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m perfect_traces_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName of recording\u001b[39m\u001b[38;5;124m'\u001b[39m][a]\n\u001b[1;32m      8\u001b[0m chan \u001b[38;5;241m=\u001b[39m perfect_traces_df\u001b[38;5;241m.\u001b[39mcell_ch\u001b[38;5;241m.\u001b[39mvalues[a]\n\u001b[1;32m      9\u001b[0m swps_keep \u001b[38;5;241m=\u001b[39m ast\u001b[38;5;241m.\u001b[39mliteral_eval(perfect_traces_df\u001b[38;5;241m.\u001b[39mswps_to_analyse\u001b[38;5;241m.\u001b[39mvalues[a])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'patcher_dict' is not defined"
     ]
    }
   ],
   "source": [
    "path = '/Users/verjim/laptop_D_17.01.2022/Schmitz_lab/data/human/'\n",
    "scaling = 1 \n",
    "unit = 'pA'\n",
    "\n",
    "a = 12\n",
    "\n",
    "filename  = path + patcher_dict[perfect_traces_df.patcher[a]] + perfect_traces_df['OP'][a] + '/' + perfect_traces_df['Name of recording'][a]\n",
    "chan = perfect_traces_df.cell_ch.values[a]\n",
    "swps_keep = ast.literal_eval(perfect_traces_df.swps_to_analyse.values[a])\n",
    "swps_delete = list(set(range(30)) - set(swps_keep))\n",
    "\n",
    "# get from h5 file\n",
    "trace = MiniTrace.from_axon_file_MP(filepath = filename,\n",
    "                                channel = chan,\n",
    "                               scaling = scaling,\n",
    "                               unit = unit,\n",
    "                               sweeps_delete = swps_delete,\n",
    "                               first_point = 0, \n",
    "                               last_point = 5500)\n",
    "\n",
    "\n",
    "plt.plot(trace.data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trace' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filter_data:\n\u001b[1;32m      5\u001b[0m     win \u001b[38;5;241m=\u001b[39m signal\u001b[38;5;241m.\u001b[39mwindows\u001b[38;5;241m.\u001b[39mhann(\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     tmplt_trace \u001b[38;5;241m=\u001b[39m signal\u001b[38;5;241m.\u001b[39mconvolve(\u001b[43mtrace\u001b[49m\u001b[38;5;241m.\u001b[39mdata, win, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28msum\u001b[39m(win)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      8\u001b[0m     tmplt_trace \u001b[38;5;241m=\u001b[39m trace\u001b[38;5;241m.\u001b[39mdata\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trace' is not defined"
     ]
    }
   ],
   "source": [
    "# For template matching it can be useful to filter the data. We use a Hann window here.\n",
    "# smoothing over the signal using a Hann window method. Understanding the math details --> not so important\n",
    "filter_data = True\n",
    "if filter_data:\n",
    "    win = signal.windows.hann(20)\n",
    "    tmplt_trace = signal.convolve(trace.data, win, mode='same') / sum(win)\n",
    "else:\n",
    "    tmplt_trace = trace.data\n",
    "\n",
    "plt.plot(trace.data, c='k', alpha=0.4)\n",
    "plt.plot(tmplt_trace)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Template matching is dependent on the waveform that is used as template. We first use a very rough estimate based on the provided window size to extract a few events from the data. We can use those to adjust the template (see below).\n",
    "\n",
    "To be able to estimate the parameters we need to scale the event. To scale it, we do a baseline subtraction, and divide by the minimum value. This assumes that the event is a negative deflection. For positive events, this needs to be change to the maximum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate roughly event shape based on window size; can be adjusted later\n",
    "win_size = 750 #default was 600\n",
    "baseline = (win_size/10) * trace.sampling\n",
    "duration = int(win_size*2/3) * trace.sampling\n",
    "t_rise = (baseline+(win_size * trace.sampling)) / 25\n",
    "t_decay = (baseline+(win_size * trace.sampling))/21\n",
    "\n",
    "template = tm.make_template(t_rise=t_rise, t_decay=t_decay, baseline=baseline, duration=duration, sampling=trace.sampling)\n",
    "\n",
    "# Run template matching to extract a few events to adjust template.\n",
    "matching = tm.template_matching(tmplt_trace, template, threshold=-4)\n",
    "print(f'found {len(matching.indices)} events')\n",
    "\n",
    "# Get average event form\n",
    "events = []\n",
    "for ind in matching.indices:\n",
    "    if ind < tmplt_trace.shape[0] - win_size:\n",
    "        events.append(tmplt_trace[ind:ind+win_size])\n",
    "events = np.array(events)\n",
    "\n",
    "mean_ev = np.mean(events, axis=0)\n",
    "\n",
    "# Scale the event\n",
    "mean_ev -= np.mean(mean_ev[0:int(win_size/10)])\n",
    "mean_ev /= np.min(mean_ev) # Needs to be adjusted for positive events.\n",
    "plt.plot(template, label='template')\n",
    "plt.plot(mean_ev,label='event')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below you can adjust the template. It does not have to be perfect, a rough fit suffices. Just change the values by which t_rise and t_decay are divided until the template and the average event more or less fit. If the event is shifted, it is also possible to shorten the duration or change values for baseline to make it fit btter. Because this is a jupyter notebook, you can just rerun the cell as many times as you need, until you found satisfactory values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Plot template and average event and use this to adjust template.\n",
    "baseline = (win_size/8) * trace.sampling - 0.0005\n",
    "duration = int(win_size*1/3) * trace.sampling\n",
    "t_rise = (baseline+(win_size * trace.sampling))/15\n",
    "t_decay = (baseline+(win_size * trace.sampling))/18\n",
    "\n",
    "template = tm.make_template(t_rise=t_rise, t_decay=t_decay, baseline=baseline, duration=duration, sampling=trace.sampling)\n",
    "plt.plot(template, label='template')\n",
    "plt.plot(mean_ev,label='event')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we extract events with a relatively high threshold (Default is -4.5). Again, performance does not need to be good, it is only important that events are not systematically missed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_label, idx, events, scores = [], [], [], []\n",
    "\n",
    "# Set the different thresholds.\n",
    "threshold_high = -5\n",
    "threshold_mid = -3\n",
    "threshold_low = -1.5\n",
    "\n",
    "\n",
    "# Run template matching with a high threshold to extract events with high confidence.\n",
    "matching = tm.template_matching(tmplt_trace, template, threshold = threshold_high)\n",
    "print(f'found {len(matching.indices)} events with high threshold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The %matplotlib inline command can be changed to %matplotlib qt to make the plot interactive and zoom into the trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib qt\n",
    "\n",
    "# Plot the output to make sure the result makes sense\n",
    "fig, axs = plt.subplots(2, 1, sharex=True)\n",
    "axs[0].plot(matching.detection_trace)\n",
    "axs[0].axhline(threshold_high, c='orange', zorder=2, ls='--')\n",
    "axs[1].plot(trace.data)\n",
    "axs[1].scatter(matching.indices, tmplt_trace[matching.indices], c='orange', zorder=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract clear events\n",
    "event_counter = 0\n",
    "for ind, location in enumerate(matching.indices):\n",
    "    if location < trace.data.shape[0] - int(win_size*1.5):\n",
    "        event = copy.deepcopy(trace.data[location:location+win_size])\n",
    "        event -= np.mean(event[:int(win_size/10)])\n",
    "        \n",
    "        cell_label.append(filename)\n",
    "        idx.append(location)\n",
    "        events.append(event)\n",
    "        scores.append(1)\n",
    "        event_counter += 1\n",
    "\n",
    "print(f'{event_counter} events extracted\\n')\n",
    "\n",
    "\n",
    "# generate list with all indices of +/- (win_size/30) points of the previously found events to prevent duplicates (or at least keep them to a minimum)\n",
    "idx_range = []\n",
    "buffer = int(win_size/30)\n",
    "for my_ind in idx:\n",
    "    idx_range += list(range(my_ind-buffer, my_ind+buffer))\n",
    "\n",
    "# Run tmplt matching with a relatively low threshold to extract FPs and small events.\n",
    "matching = tm.template_matching(tmplt_trace, template, threshold=threshold_mid)\n",
    "print(f'found {len(matching.indices)} events with mid threshold')\n",
    "unclear_counter = 0\n",
    "for ind, location in enumerate(matching.indices):\n",
    "    if location < trace.data.shape[0] - int(win_size*1.5):\n",
    "        if location not in idx_range:\n",
    "            event = copy.deepcopy(trace.data[location:location+win_size])\n",
    "            event -= np.mean(event[:int(win_size/10)])\n",
    "            \n",
    "            cell_label.append(filename)\n",
    "            idx.append(location)\n",
    "            events.append(event)\n",
    "            scores.append(2)\n",
    "            unclear_counter += 1\n",
    "\n",
    "print(f'{unclear_counter} unclear events extracted\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run tmplt matching with a very low threshold. Remaining parts of the trace should be event free.\n",
    "matching = tm.template_matching(tmplt_trace, template, threshold=threshold_low)\n",
    "print(f'found {len(matching.indices)} events with low threshold')\n",
    "\n",
    "event_free_indices = []\n",
    "for i in range(matching.indices.shape[0]-1):\n",
    "    start = matching.indices[i] + win_size\n",
    "    end = matching.indices[i+1] - win_size\n",
    "    if end - start > 0:\n",
    "        event_free_indices.append(np.arange(start, end))\n",
    "\n",
    "event_free_indices = np.concatenate(event_free_indices)\n",
    "unique_stretches = []\n",
    "for ind, i in enumerate(event_free_indices):\n",
    "    if ind==0:\n",
    "        unique_stretches.append(i)\n",
    "        next_possible = i+win_size\n",
    "    \n",
    "    if i < next_possible:\n",
    "        pass\n",
    "    else:\n",
    "        unique_stretches.append(i)\n",
    "        next_possible = i+win_size\n",
    "\n",
    "# Extract unique stretches to prevent overlap and redundancy in the data\n",
    "if len(unique_stretches) <= event_counter:\n",
    "    inds = np.array(unique_stretches)\n",
    "else:\n",
    "    inds = np.random.choice(np.array(unique_stretches), event_counter, replace=False)\n",
    "\n",
    "# Extract events\n",
    "noise_counter = 0\n",
    "for location in sorted(inds):\n",
    "    event = copy.deepcopy(trace.data[location:location+win_size])\n",
    "    event -= np.mean(event[:int(win_size/10)])\n",
    "    cell_label.append(filename)\n",
    "    idx.append(location)\n",
    "    events.append(event)\n",
    "    scores.append(0)\n",
    "    noise_counter += 1\n",
    "\n",
    "print(f'{noise_counter} noise stretches extracted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_id = 'Oct_2024_train/' + str(a) + '_' + filename[filename.rfind('/') +1 : -4] + '_ch' +str(chan)\n",
    "\n",
    "if len(events)  > 201:\n",
    "    val = 200\n",
    "else:\n",
    "    val = len(events)\n",
    "    \n",
    "# Save the result\n",
    "x = np.array(events[:val])\n",
    "y = np.array(scores[:val])\n",
    "indices = np.array(idx[:val])\n",
    "\n",
    "save_dataset = f'./output/{save_id}_example_training_data.h5'\n",
    "\n",
    "if save_dataset:\n",
    "    with h5py.File(save_dataset, 'w') as f:\n",
    "        f.create_dataset(\"events\", data = x)\n",
    "        f.create_dataset(\"scores\", data = y)\n",
    "        f.create_dataset(\"raw_indices\", data = indices)\n",
    "        f.create_dataset(\"cell_label\", data = np.array(cell_label[:val], dtype='S'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save only noise stretches\n",
    "\n",
    "noise_dataset = './output/Oct_2024_train/noise/' + str(a) + '_' + filename[filename.rfind('/') +1 : -4] + '_ch' +str(chan) + '_noise.h5'\n",
    "\n",
    " \n",
    "noise = np.take(events, np.where(np.array(scores) == 0)[0], axis = 0)[:60]\n",
    "noise_scores = np.repeat([0], 60)\n",
    "idx_noise = np.array(idx)[np.where(np.array(scores) == 0)[0][:60]]\n",
    "cell_labels_noise = np.array(cell_label)[np.where(np.array(scores) == 0)[0][:60]]\n",
    "\n",
    "with h5py.File(noise_dataset, 'w') as f:\n",
    "    f.create_dataset(\"events\", data = noise)\n",
    "    f.create_dataset(\"scores\", data = noise_scores)\n",
    "    f.create_dataset(\"raw_indices\", data = idx_noise)\n",
    "    f.create_dataset(\"cell_label\", data = np.array(cell_labels_noise, dtype='S'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
