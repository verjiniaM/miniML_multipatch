{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to miniML_clean (Python 3.10.14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import sys\n",
    "sys.path.append('../../core/')\n",
    "import template_matching as tm\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.read_excel('/Users/verjim/laptop_D_17.01.2022/Schmitz_lab/results/human/data/miniML/events_eval_training2.xlsx')\n",
    "output_folder = '/Users/verjim/miniML_data/data/model_training_round_2/'\n",
    "\n",
    "# for extraction of noise stretches\n",
    "win_size = 750\n",
    "trace_sampling = 20_000\n",
    "threshold_low = -1.5\n",
    "\n",
    "baseline = (win_size/8) * trace_sampling - 0.0005\n",
    "duration = int(win_size*1/3) * trace_sampling\n",
    "t_rise = (baseline+(win_size * trace_sampling))/15\n",
    "t_decay = (baseline+(win_size * trace_sampling))/18\n",
    "\n",
    "template = tm.make_template(t_rise=t_rise, t_decay=t_decay, baseline=baseline, duration=duration, sampling=trace_sampling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_index (data_file, x, score, label):\n",
    "    with h5py.File('/Users/verjim/miniML_data/data/' + data_file, 'r') as f:\n",
    "        # Access trace group and its datasets\n",
    "        trace_group = f['trace_']\n",
    "        trace_time = trace_group['trace_time'][:]\n",
    "        trace_data = trace_group['trace_data'][:]\n",
    "\n",
    "    closest_index = np.abs(trace_time - x).argmin()\n",
    "    #x_data = trace_time[closest_index-150 : closest_index+599]\n",
    "    event_trace = trace_data[closest_index-150 : closest_index+599]\n",
    "    plt.plot(event_trace)\n",
    "\n",
    "    return event_trace, score, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem with slice 2024_Nov_1122127035.abf1_model_comparison.h5\n",
      "5\n",
      "problem with slice 2024_Nov_1122519021.abf5_model_comparison.h5\n",
      "361\n",
      "problem with slice 2024_Nov_1123817064.abf4_model_comparison.h5\n",
      "362\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df_eval)):\n",
    "    score = df_eval.score[i]\n",
    "    label = df_eval.label[i]\n",
    "    if score == 1 and label != 'false negative':\n",
    "        print('problem with slice ' + df_eval.data_file[i])\n",
    "        print(i)\n",
    "    if score == 0 and label != 'false positive':\n",
    "        print('problem with slice ' + df_eval.data_file[i])\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_only = ['2024_Nov_1122519021.abf5_model_comparison.h5', \\\n",
    "              '2024_Nov_1123817064.abf4_model_comparison.h5', \\\n",
    "                '2024_Nov_1122427028.abf5_model_comparison.h5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '/Users/verjim/miniML_data/data/'\n",
    "traces, labels, scores, fn_chan, noise_locs  = [], [], [], [], []\n",
    "for a, file in enumerate(df_eval.data_file.unique()[:-1]):\n",
    "    df_fn = df_eval[df_eval.data_file == file].reset_index(drop = True)\n",
    "    # load traces and event peaks\n",
    "    with h5py.File(data_folder + df_fn.data_file[0], 'r') as f:\n",
    "        model_2 = f['model_2']\n",
    "        event_peaks_2 = model_2['event_peaks2'][:] # X\n",
    "\n",
    "        trace_group = f['trace_']\n",
    "        #trace_time = trace_group['trace_time'][:]\n",
    "        trace_data = trace_group['trace_data'][:]\n",
    "        fn = trace_group.attrs['filename']\n",
    "        chan = trace_group.attrs['chan']\n",
    "\n",
    "    if file == '2024_Nov_1123209020.abf6_model_comparison.h5':\n",
    "        trace_data = trace_data[:192 * 20_000]\n",
    "        event_peaks_2 = event_peaks_2[event_peaks_2 < 190]\n",
    "\n",
    "    if file == '2024_Nov_112021_03_25_0058.abf2_model_comparison.h5':\n",
    "        trace_data = trace_data[:80 * 20_000]\n",
    "        event_peaks_2 = event_peaks_2[event_peaks_2 < 80]\n",
    "\n",
    "    # find false positives\n",
    "    FPs = (df_fn.x[df_fn.label == 'false positive'].reset_index(drop = True).values * 20_000).astype(int)\n",
    "    all_events_miniML = (event_peaks_2 * 20_000).astype(int)\n",
    "    for fp in FPs:\n",
    "        diffs = all_events_miniML - fp\n",
    "    \n",
    "    # find events that are close to false positives\n",
    "    indx_del = np.where((diffs >= -150) & (diffs <= 150))[0] \n",
    "    if fn in noise_only:\n",
    "        true_nice_events = np.empty(0)\n",
    "    else:\n",
    "        true_nice_events = np.delete(all_events_miniML, indx_del) # delete them form the dataset \n",
    "\n",
    "    # chose same number of events from each filename\n",
    "    count_ = int(300/ len(df_eval.data_file.unique()) + 15)\n",
    "    if len(true_nice_events) <= count_ + 40:\n",
    "        true_nice_events = true_nice_events\n",
    "    else:\n",
    "        true_nice_events = np.random.choice(true_nice_events, count_ + 40, replace = False)\n",
    "\n",
    "    # flse negatives - same procedure\n",
    "    FNs = (df_fn.x[df_fn.label == 'false negative'].values * 20_000).astype(int)\n",
    "    all_event_indx = np.concatenate([FPs, true_nice_events, FNs])\n",
    "    for k, x in enumerate(all_event_indx):\n",
    "        #trace_dp = trace_time * 20_000\n",
    "        if len(trace_data[x - 150 : x + 600]) != 750:\n",
    "            print('problem with slice ' + df_fn.data_file[0] + 'at ' + str(x))  \n",
    "        traces.append(trace_data[x - 150 : x + 600])\n",
    "\n",
    "    # create labels\n",
    "    FP_labels = ['FP; by model'] * len(FPs)\n",
    "    FP_score = [0] * len(FPs)\n",
    "\n",
    "    nice_events_labels = ['nice events'] * len(true_nice_events)\n",
    "    nice_events_scores = [1] * len(true_nice_events)\n",
    "\n",
    "    FN_labels = ['missed events'] * len(FNs)\n",
    "    FN_scores = [1] * len(FNs)\n",
    "\n",
    "    labels = labels + FP_labels + nice_events_labels + FN_labels\n",
    "    scores = scores + FP_score + nice_events_scores + FN_scores\n",
    "    fn_chan = fn_chan + [fn + '_' + chan] * len(FP_score + nice_events_scores + FN_scores)\n",
    "\n",
    "    # extract noise stretches\n",
    "    event_free_indices = []\n",
    "    for k, x in enumerate(sorted(all_event_indx)):\n",
    "        if k == len(all_event_indx) - 1:\n",
    "            continue\n",
    "        start = x + 600\n",
    "        end = (all_event_indx[k + 1] - 150)\n",
    "        if end - start > 0:\n",
    "            event_free_indices.append(np.arange(start, end))\n",
    "\n",
    "    event_free_indices = np.concatenate(event_free_indices)\n",
    "    unique_stretches = []\n",
    "    for ind, i in enumerate(event_free_indices):\n",
    "        if ind==0:\n",
    "            unique_stretches.append(i)\n",
    "            next_possible = i+win_size\n",
    "        \n",
    "        if i < next_possible:\n",
    "            pass\n",
    "        else:\n",
    "            unique_stretches.append(i)\n",
    "            next_possible = i+win_size\n",
    "\n",
    "    # Extract same number of unique noise stretches from each fn\n",
    "    if len(unique_stretches) <= count_:\n",
    "        inds = np.array(unique_stretches)\n",
    "    else:\n",
    "        inds = np.random.choice(np.array(unique_stretches), count_, replace=False)\n",
    "\n",
    "    # Collect noise stretche\n",
    "    noise_counter = 0\n",
    "    for location in sorted(inds):\n",
    "        event = copy.deepcopy(trace_data[location:location+win_size])\n",
    "        event -= np.mean(event[:int(win_size/10)])\n",
    "\n",
    "        traces.append(event)\n",
    "        labels.append('noise')\n",
    "        scores.append(0)\n",
    "        fn_chan.append(fn + '_' + chan)\n",
    "        \n",
    "        noise_locs.append(location)\n",
    "        noise_counter += 1\n",
    "        \n",
    "traces = np.vstack(traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nice events : 352 score 1\n",
      "missed events : 303 score 1\n",
      "FP; by model : 135 score 0\n",
      "noise : 384 score 0\n",
      "All events : 1174\n"
     ]
    }
   ],
   "source": [
    "print('nice events :', labels.count('nice events'), 'score 1')\n",
    "print('missed events :', labels.count('missed events'), 'score 1')\n",
    "print('FP; by model :', labels.count('FP; by model'), 'score 0')\n",
    "print('noise :', labels.count('noise'), 'score 0')\n",
    "\n",
    "print('All events :', len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything saved to /Users/verjim/miniML_data/data/model_training_round_2/\n"
     ]
    }
   ],
   "source": [
    "# save the results\n",
    "\n",
    "with h5py.File(output_folder + file[:-33] + '_all_types_of_events_to_check.h5', 'w') as f:\n",
    "    f.create_dataset(\"events\", data = traces)\n",
    "    f.create_dataset(\"scores\", data = scores)\n",
    "    f.create_dataset(\"labels\", data = labels)\n",
    "    f.create_dataset(\"filename and chan\", data = fn_chan)\n",
    "\n",
    "print(f\"Everything saved to {output_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise estiamtion on specific traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_name = '2024_Nov_1124117016.abf7_model_comparison.h5' \n",
    "\n",
    "data_folder = '/Users/verjim/miniML_data/data/'\n",
    "traces, labels, scores, fn_chan, noise_locs  = [], [], [], [], []\n",
    "with h5py.File(data_folder + trace_name, 'r') as f:\n",
    "    model_2 = f['model_2']\n",
    "    event_peaks_2 = model_2['event_peaks2'][:] # X\n",
    "\n",
    "    trace_group = f['trace_']\n",
    "    #trace_time = trace_group['trace_time'][:]\n",
    "    trace_data = trace_group['trace_data'][:]\n",
    "    fn = trace_group.attrs['filename']\n",
    "    chan = trace_group.attrs['chan']\n",
    "\n",
    "all_events_miniML = (event_peaks_2 * 20_000).astype(int)\n",
    "\n",
    "# extract noise stretches\n",
    "event_free_indices = []\n",
    "for k, x in enumerate(sorted(all_event_indx)):\n",
    "    if k == len(all_event_indx) - 1:\n",
    "        continue\n",
    "    start = x + 600\n",
    "    end = (all_event_indx[k + 1] - 150)\n",
    "    if end - start > 0:\n",
    "        event_free_indices.append(np.arange(start, end))\n",
    "\n",
    "event_free_indices = np.concatenate(event_free_indices)\n",
    "unique_stretches = []\n",
    "for ind, i in enumerate(event_free_indices):\n",
    "    if ind==0:\n",
    "        unique_stretches.append(i)\n",
    "        next_possible = i+win_size\n",
    "        \n",
    "    if i < next_possible:\n",
    "        pass\n",
    "    else:\n",
    "        unique_stretches.append(i)\n",
    "        next_possible = i+win_size\n",
    "        \n",
    "inds = np.array(unique_stretches)\n",
    "# Extract events\n",
    "noise_counter = 0\n",
    "for location in sorted(inds):\n",
    "    event = copy.deepcopy(trace_data[location:location+win_size])\n",
    "    event -= np.mean(event[:int(win_size/10)])\n",
    "\n",
    "    traces.append(event)\n",
    "    labels.append('noise')\n",
    "    scores.append(0)\n",
    "    fn_chan.append(fn_chan)\n",
    "    \n",
    "    noise_locs.append(location)\n",
    "    noise_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_traces = np.concatenate(traces)\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(concatenated_traces)\n",
    "plt.title('Noise ' + trace_name)\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.show()\n",
    "\n",
    "# Calculate the standard deviation\n",
    "std_dev = np.std(concatenated_traces)\n",
    "print(\"Standard Deviation:\", std_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '2024_Nov_1124117016.abf7_model_comparison.h5' - stdv = 6.3848 of all noise stretches \n",
    "# visually the signal looked unstable and it was difficult to tell apart events from nooise - random fluctuations in the signal\n",
    "\n",
    "# '2024_Nov_1124411036.abf3_model_comparison.h5' - stdv = 6.3095 of all noise stretches\n",
    "# visually the trace is very stable, looks ideal\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
